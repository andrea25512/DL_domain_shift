# ImageNet-A Domain Shift Project

This project investigates the domain shift robustness of deep learning models using the ImageNet-A dataset, with a focus on improving performance from a MEMO baseline through novel approaches such as SimCLR.
The project consists of multiple Google Colab runnable stages, starting with baseline evaluations using pre-trained models and progressing towards implementing and experimenting with advanced techniques.

# Dataset

The project uses the ImageNet-A dataset, which contains adversarial examples.
This dataset is not publicly available since it was provided by a professor through a restricted Google Drive link. 
Access to the dataset is limited to those with university accounts authorized by the professor, making it unavailable for general public access.
Although, adapting the code to be able to load the datast from another source should not cause any problems.

# Baseline Models
### ResNet-50

The first step in the project involved evaluating the performance of a pre-trained ResNet-50 model on the ImageNet-A dataset. 
The PyTorch implementation of ResNet-50 was used as a baseline to understand the failure rate on adversarial examples, which is expected to be high given the nature of the dataset.

### Memo

The next baseline involved the Memo approach, focusing on augmentation, marginal entropy and batch normalization. 
This model, while not novel, was partially re-implemented from scratch with some guidance from the original projectâ€™s GitHub repository, which is appropriately credited in the Jupyter Notebook. 
Key components of this model include:
- Augmentation: In line with the original paper's implementation, the AugMix method is applied to square-cropped patches of the original image. This process involves multiple branches where different augmentations are randomly applied and the merged togeder in one single image, ensuring that each iteration produces a slightly different version of the image using a single, consistent method.
- Marginal Entropy: Implemented to match the description from the original paper, this method drives the primary function of the Memo model's loss, since the labels can't be accessed.
- Batch Normalization: Also based on the original paper, batch normalization was re-implemented to improve the model's robustness, and to avoid overfitting when having a backpropagation on a set of augmentations of one sample.

# Novel Approach: SimCLR Integration

Building upon the Memo baseline, we introduced an innovative approach by integrating SimCLR for contrastive learning, by comparing pairs of augmented images. 
This approach involves:
- Encoder: responsible for extracting features from the input images. It uses a pre-trained neural network (in our case - ResNet) from which the last fully connected layers (FC) are removed, keeping only the convolutional layers that extract useful features.
- Projection Head: takes these extracted features and projects them into a smaller, linear latent space. This space is used to calculate the contrastive loss. The ReLU activation function introduces non-linearity that helps to create more discriminative representations.
- NT-Xent Loss: Projections are normalized to have unit size, and the cosine similarity between all pairs of representations is calculated, using a temperature parameter that controls the similarity scale. The loss is calculated by averaging the losses computed in both directions via cross-entropy for all positive pairs in the batch.
- Memo Block: 64 augmentations are generated for each image using augmix. These augmented images are transformed into a batch and passed through the model to make predictions. The marginal entropy loss is calculated on the model outputs, followed by the backpropagation step and updating the model weights.
- SimCLR Block: Next, an encoder and a projection head are created. Two sets of augmentations are generated for contrastive learning (32 augmentations per set) and these augmentations are passed through the encoder and projection head (*using the model generated by the memo block*). The contrastive loss is calculated on the projected representations, followed by another backpropagation step and a further update of the model weights.
- Final Prediction: After the SimCLR block, the model is put in evaluation mode and a final prediction is made on the original image.

# Failed Experiments

During the project, several experiments did not yield successful results:
- Augmentation applied in Patches: An attempt was made to generate a new type of augmentation by dividing the original image into patches, applying different augmentations to each patch, and then reconstructing the original image. However, this method caused discontinuities at the patch boundaries and did not improve model performance.
- Teacher-Student Model: A teacher-student approach was explored but failed to enhance robustness. It is suspected that the reference teacher model was not strong enough, resulting in the student model inheriting its limitations.
- Generative Models: Efforts to incorporate generative models were unsuccessful. Descriptions generated by Blip often did not accurately represent the content of the original image, leading to poor results.

# Testing Constraints

One critical aspect of this project is the testing constraint: Test-Time Adaptation (TTA).
The goal is to develop a method for TTA that enhances the predictive capabilities of a network on test samples without having access to the labels of the test samples or the remaining data. Before analyzing each new sample, the state of the network must be reset to its initial configuration (i.e., reloading the pre-trained weights).
